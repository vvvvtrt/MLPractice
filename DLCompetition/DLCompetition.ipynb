{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Соревнонание по DL"
      ],
      "metadata": {
        "id": "UQ-4YJF3yFJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Первое решение CNN + LSTM"
      ],
      "metadata": {
        "id": "PmNW0kAQxxvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Идея заключается в том, что каждый рассматривая sequence_id как временной ряд показаний акселерометра и гироскопа. Для этого последовательности приводятся к фиксированной длине и подаются в гибридную модель CNN+LSTM: сверточная часть извлекает локальные паттерны движений, а LSTM моделирует их временную динамику. Полученные признаки объединяются и используются для классификации одной из 6 активностей\n",
        "\n",
        "**accuracy в kaggle: 0.846**"
      ],
      "metadata": {
        "id": "Sfkd8XOPyAjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "h3n_vcODyboI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка и группировка"
      ],
      "metadata": {
        "id": "WP2NybTtyg3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "le = LabelEncoder()\n",
        "train_df['gesture_encoded'] = le.fit_transform(train_df['gesture'])\n",
        "num_classes = len(le.classes_)"
      ],
      "metadata": {
        "id": "tB6c2CbzyixZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def group_sequences(df, include_labels=True):\n",
        "    seq_dict = {}\n",
        "    for seq_id, group in df.groupby('sequence_id'):\n",
        "        X = group[['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z']].values.astype(np.float32)\n",
        "        if include_labels:\n",
        "            y = group['gesture_encoded'].iloc[0]\n",
        "            seq_dict[seq_id] = (X, y)\n",
        "        else:\n",
        "            seq_dict[seq_id] = X\n",
        "    return seq_dict"
      ],
      "metadata": {
        "id": "3yMLLWSmytG2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_seq = group_sequences(train_df, include_labels=True)\n",
        "test_seq = group_sequences(test_df, include_labels=False)"
      ],
      "metadata": {
        "id": "cTJGGDLOyt9m"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Паддинг до фикс. длины"
      ],
      "metadata": {
        "id": "lKCgzJ4o9_xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128"
      ],
      "metadata": {
        "id": "LWAjP_6Dyytr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_to_max_len(X, max_len=MAX_LEN):\n",
        "    if len(X) > max_len:\n",
        "        return X[:max_len]\n",
        "    else:\n",
        "        pad = np.zeros((max_len - len(X), X.shape[1]), dtype=np.float32)\n",
        "        return np.concatenate([X, pad], axis=0)"
      ],
      "metadata": {
        "id": "2469mA29y0bV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, train_ids = [], [], []\n",
        "for seq_id, (X, y) in train_seq.items():\n",
        "    X_train.append(pad_to_max_len(X))\n",
        "    y_train.append(y)\n",
        "    train_ids.append(seq_id)\n",
        "\n",
        "X_test, test_ids = [], []\n",
        "for seq_id, X in test_seq.items():\n",
        "    X_test.append(pad_to_max_len(X))\n",
        "    test_ids.append(seq_id)\n"
      ],
      "metadata": {
        "id": "5glSf5f0y6XV"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor(np.stack(X_train))\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test = torch.tensor(np.stack(X_test))"
      ],
      "metadata": {
        "id": "UMXf7ntDy-Zo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель на pytorch"
      ],
      "metadata": {
        "id": "_7f1IwvazE6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_LSTM(nn.Module):\n",
        "    def __init__(self, input_dim=7, seq_len=128, num_classes=6):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(input_dim, 64, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_dim, 64, batch_first=True)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128 + 64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_t = x.permute(0, 2, 1)\n",
        "\n",
        "        c = torch.relu(self.conv1(x_t))\n",
        "        c = torch.relu(self.conv2(c))\n",
        "        c = self.pool(c).squeeze(-1)\n",
        "\n",
        "        _, (h, _) = self.lstm(x)\n",
        "        l = h.squeeze(0)\n",
        "\n",
        "        combined = torch.cat([c, l], dim=1)\n",
        "        out = self.classifier(combined)\n",
        "        return out"
      ],
      "metadata": {
        "id": "feodsL3izJ2K"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение"
      ],
      "metadata": {
        "id": "Ivx_yLhSzb-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CNN_LSTM(num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "1lKQPurezfoa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "6-ngpxvizgqJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "\n",
        "for epoch in range(25):\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Loss: {total_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6koQeEk9zaTC",
        "outputId": "f7b45b37-1d92-4bf5-e9d3-a2277998c775"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 8/8 [00:00<00:00, 25.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.7581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 8/8 [00:00<00:00, 28.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.6899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 8/8 [00:00<00:00, 37.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.6417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 8/8 [00:00<00:00, 36.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.5439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 8/8 [00:00<00:00, 36.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.4250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 8/8 [00:00<00:00, 33.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.2962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 8/8 [00:00<00:00, 36.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.1259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 8/8 [00:00<00:00, 35.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.0379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 8/8 [00:00<00:00, 36.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.9950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 8/8 [00:00<00:00, 34.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.8837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 8/8 [00:00<00:00, 37.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.8550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 8/8 [00:00<00:00, 38.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.8263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 8/8 [00:00<00:00, 37.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.7577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 8/8 [00:00<00:00, 37.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 8/8 [00:00<00:00, 36.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 8/8 [00:00<00:00, 38.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.5910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 8/8 [00:00<00:00, 38.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.5416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 8/8 [00:00<00:00, 38.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.5111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 8/8 [00:00<00:00, 37.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.4757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 8/8 [00:00<00:00, 36.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.4212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 8/8 [00:00<00:00, 38.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.4105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 8/8 [00:00<00:00, 35.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.3990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 8/8 [00:00<00:00, 36.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.3615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 8/8 [00:00<00:00, 34.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.3860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 8/8 [00:00<00:00, 36.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.3205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предсказание и сабмит"
      ],
      "metadata": {
        "id": "tEqeMgBjznMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_loader = DataLoader(torch.utils.data.TensorDataset(X_test), batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "vMBBV11Azr3T"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for (X_batch,) in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        outputs = model(X_batch)\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)"
      ],
      "metadata": {
        "id": "o0CJ7xuazvYv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seqid_to_pred = dict(zip(test_ids, all_preds))\n",
        "default_class = np.bincount(y_train.numpy()).argmax()"
      ],
      "metadata": {
        "id": "z8ki4zkmzw6a"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sub = pd.read_csv('sample_submission.csv')\n",
        "sample_sub['gesture'] = sample_sub['sequence_id'].apply(\n",
        "    lambda sid: le.inverse_transform([seqid_to_pred.get(sid, default_class)])[0]\n",
        ")\n",
        "sample_sub.to_csv('submission_torch.csv', index=False)"
      ],
      "metadata": {
        "id": "W26Yr0wjzmuF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Второе решение: CNN + LSTM с Attention и CatBoost (Stacking)"
      ],
      "metadata": {
        "id": "QTGArk-5yRg_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Каждая последовательность сенсорных данных приводится к фиксированной длине и обрабатывается нейросетевой моделью CNN + двунаправленный LSTM с механизмом attention, где CNN извлекает локальные паттерны движения, а attention позволяет модели фокусироваться на наиболее информативных временных участках последовательности. Для повышения качества используются OOF-предсказания нейросети (softmax-вероятности), которые объединяются с простыми статистическими (handcrafted) признаками и подаются в CatBoost-классификатор в рамках стэкинга\n",
        "\n",
        "**accuracy в kaggle: 0.916**"
      ],
      "metadata": {
        "id": "FrxiPKl75rvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkAd5moD3UGt",
        "outputId": "77652226-e63e-4e7b-9789-1b68517c0994"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from catboost import CatBoostClassifier\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "SgT9T7Eu7cL8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Загрузка и подготовка данных"
      ],
      "metadata": {
        "id": "R_KYe_5Y7ecL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df  = pd.read_csv('test.csv')\n",
        "\n",
        "le = LabelEncoder()\n",
        "train_df['gesture_encoded'] = le.fit_transform(train_df['gesture'])\n",
        "num_classes = len(le.classes_)\n",
        "\n",
        "FEATURES = ['acc_x','acc_y','acc_z','rot_w','rot_x','rot_y','rot_z']\n",
        "MAX_LEN = 128"
      ],
      "metadata": {
        "id": "zqKXsGed7eM4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def group_sequences(df, with_labels=True):\n",
        "    out = {}\n",
        "    for sid, g in df.groupby('sequence_id'):\n",
        "        X = g[FEATURES].values.astype(np.float32)\n",
        "        if with_labels:\n",
        "            out[sid] = (X, g['gesture_encoded'].iloc[0])\n",
        "        else:\n",
        "            out[sid] = X\n",
        "    return out"
      ],
      "metadata": {
        "id": "nnBlktiP7iGj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad(X):\n",
        "    if len(X) >= MAX_LEN:\n",
        "        return X[:MAX_LEN]\n",
        "    return np.vstack([X, np.zeros((MAX_LEN-len(X), X.shape[1]), np.float32)])"
      ],
      "metadata": {
        "id": "awcwu-my7lk9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_seq = group_sequences(train_df, True)\n",
        "test_seq  = group_sequences(test_df, False)"
      ],
      "metadata": {
        "id": "Sm4gEiUS7n4m"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, train_ids = [], [], []\n",
        "for sid, (X,y) in train_seq.items():\n",
        "    X_train.append(pad(X))\n",
        "    y_train.append(y)\n",
        "    train_ids.append(sid)\n",
        "\n",
        "X_test, test_ids = [], []\n",
        "for sid, X in test_seq.items():\n",
        "    X_test.append(pad(X))\n",
        "    test_ids.append(sid)\n",
        "\n",
        "X_train = torch.tensor(np.stack(X_train))\n",
        "y_train = torch.tensor(y_train)\n",
        "X_test  = torch.tensor(np.stack(X_test))"
      ],
      "metadata": {
        "id": "KErxfBr77qsF"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handcrafted признаки дополнительно к имеющимся"
      ],
      "metadata": {
        "id": "kzMad1zz8etL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handcrafted(X):\n",
        "    return np.concatenate([\n",
        "        X.mean(0),\n",
        "        X.std(0),\n",
        "        X.min(0),\n",
        "        X.max(0)\n",
        "    ])"
      ],
      "metadata": {
        "id": "U8UbJ2kV8d-k"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hc_train = np.stack([handcrafted(x.numpy()) for x in X_train])\n",
        "hc_test  = np.stack([handcrafted(x.numpy()) for x in X_test])"
      ],
      "metadata": {
        "id": "rpSjqXNn8n6W"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention, который должн помоч в выделении ключевых признаков"
      ],
      "metadata": {
        "id": "BzO07q0D8u7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, T, H)\n",
        "        weights = torch.softmax(self.attn(x).squeeze(-1), dim=1)\n",
        "        return torch.sum(x * weights.unsqueeze(-1), dim=1)"
      ],
      "metadata": {
        "id": "oAGKW9eG8wq_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN + LSTM + Attention"
      ],
      "metadata": {
        "id": "rg135C_79PA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_LSTM_Attn(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(7, 64, 5, padding=2)\n",
        "        self.conv2 = nn.Conv1d(64, 128, 3, padding=1)\n",
        "        self.pool  = nn.AdaptiveMaxPool1d(1)\n",
        "\n",
        "        self.lstm  = nn.LSTM(7, 64, batch_first=True, bidirectional=True)\n",
        "        self.attn  = Attention(128)\n",
        "\n",
        "        self.fc = nn.Linear(128 + 128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN\n",
        "        x_t = x.permute(0,2,1)\n",
        "        c = torch.relu(self.conv1(x_t))\n",
        "        c = torch.relu(self.conv2(c))\n",
        "        c = self.pool(c).squeeze(-1)\n",
        "\n",
        "        # LSTM + Attention\n",
        "        l, _ = self.lstm(x)\n",
        "        a = self.attn(l)\n",
        "\n",
        "        return self.fc(torch.cat([c, a], dim=1))\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "agLELTpr8yiq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OOF NN предсказания"
      ],
      "metadata": {
        "id": "krVAx9MR9NRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(5, shuffle=True, random_state=42)\n",
        "\n",
        "oof_nn  = np.zeros((len(X_train), num_classes))\n",
        "test_nn = np.zeros((len(X_test), num_classes))"
      ],
      "metadata": {
        "id": "w2ymRAxC9Nq4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fold, (tr, val) in enumerate(skf.split(X_train, y_train)):\n",
        "    print(f'\\nFold {fold+1}')\n",
        "\n",
        "    model = CNN_LSTM_Attn(num_classes).to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    tr_loader = DataLoader(TensorDataset(X_train[tr], y_train[tr]), 32, True)\n",
        "    val_loader = DataLoader(TensorDataset(X_train[val], y_train[val]), 64, False)\n",
        "    test_loader = DataLoader(TensorDataset(X_test), 64, False)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(20):\n",
        "        for xb, yb in tr_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            loss = loss_fn(model(xb), yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # OOF\n",
        "        idx = 0\n",
        "        for xb, yb in val_loader:\n",
        "            xb = xb.to(device)\n",
        "            probs = torch.softmax(model(xb),1).cpu().numpy()\n",
        "            oof_nn[val[idx:idx+len(probs)]] = probs\n",
        "            idx += len(probs)\n",
        "\n",
        "        # TEST\n",
        "        fold_test = []\n",
        "        for xb, in test_loader:\n",
        "            xb = xb.to(device)\n",
        "            fold_test.append(torch.softmax(model(xb),1).cpu().numpy())\n",
        "        test_nn += np.vstack(fold_test) / skf.n_splits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLyhoklS9hpi",
        "outputId": "be5e0b99-c35f-4c1c-d71b-d73b84665a5b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n",
            "\n",
            "Fold 2\n",
            "\n",
            "Fold 3\n",
            "\n",
            "Fold 4\n",
            "\n",
            "Fold 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CatBoost stacking"
      ],
      "metadata": {
        "id": "mxsJwEDQ9o2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meta_train = np.hstack([oof_nn, hc_train])\n",
        "meta_test  = np.hstack([test_nn, hc_test])\n",
        "\n",
        "cat = CatBoostClassifier(\n",
        "    iterations=2000,\n",
        "    depth=8,\n",
        "    learning_rate=0.03,\n",
        "    loss_function='MultiClass',\n",
        "    eval_metric='Accuracy',\n",
        "    random_seed=42,\n",
        "    verbose=200\n",
        ")\n",
        "\n",
        "cat.fit(meta_train, y_train.numpy())\n",
        "\n",
        "test_pred = cat.predict(meta_test).astype(int).flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5B_0ibd9nos",
        "outputId": "898cf1ff-aeed-4cb0-800b-ae603bea1a89"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.7764706\ttotal: 90.7ms\tremaining: 3m 1s\n",
            "200:\tlearn: 0.9921569\ttotal: 27.4s\tremaining: 4m 4s\n",
            "400:\tlearn: 1.0000000\ttotal: 45.1s\tremaining: 2m 59s\n",
            "600:\tlearn: 1.0000000\ttotal: 1m 3s\tremaining: 2m 27s\n",
            "800:\tlearn: 1.0000000\ttotal: 1m 20s\tremaining: 2m\n",
            "1000:\tlearn: 1.0000000\ttotal: 1m 38s\tremaining: 1m 38s\n",
            "1200:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 1m 18s\n",
            "1400:\tlearn: 1.0000000\ttotal: 2m 15s\tremaining: 58.1s\n",
            "1600:\tlearn: 1.0000000\ttotal: 2m 33s\tremaining: 38.3s\n",
            "1800:\tlearn: 1.0000000\ttotal: 2m 51s\tremaining: 18.9s\n",
            "1999:\tlearn: 1.0000000\ttotal: 3m 9s\tremaining: 0us\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сабмит"
      ],
      "metadata": {
        "id": "79R_5e0o929V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.read_csv('sample_submission.csv')\n",
        "pred_map = dict(zip(test_ids, test_pred))\n",
        "default = np.bincount(y_train.numpy()).argmax()\n",
        "\n",
        "sub['gesture'] = sub['sequence_id'].apply(\n",
        "    lambda x: le.inverse_transform([pred_map.get(x, default)])[0]\n",
        ")\n",
        "\n",
        "sub.to_csv('submission_catboost_attention.csv', index=False)\n",
        "print('Saved submission_catboost_attention.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QRkA__k94zW",
        "outputId": "9a77f952-6947-47f6-9ffc-c5c12b32a7b0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_catboost_attention.csv\n"
          ]
        }
      ]
    }
  ]
}
